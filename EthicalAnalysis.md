# An Ethical Analysis of Using Generative AI for Political Means

The following examines the New York Times article, "How ChatGPT Hijacks Democracy", written by Nathan E. Sanders and Bruce Schneier. The purpose of the response below is to provide reasoning on the ethical dilemma: Is it ethical to use generative AI for government lobbying or other areas of political influence, as described in the article?

***

</br></br>
The article, "How ChatGPT Hijacks Democracy". written by Nathan E. Sanders and Bruce Schneier brings forth issues of the power Artificial Intelligence may bring to politics. Notably, these issues include the ability for AI to represent a wide variety of political issues that have do not impact the AI model and the replacement of humans in democratic processes. THe article highlights a notable issue regarding the use of AI in the political sphere, stating "...an AI system with the sophistication of ChatGPT but trained on relevant data could selectively target key legislators and influencers to identify the weakest points in the policymaking system and ruthlessly exploit them through direct communication, public relations campaigns, horse trading or other points of leverage."
</br></br>
However, we still must answer the question: Is it ethical to use generative AI for government lobbying or other areas of political influence, as described in the article? This, is a difficult problem to answer because one could argue both pros and cons for implementing AI for government lobbying. However, I would argue that introducing generative AI as a political force would be a recipe for disaster. 
</br></br>
One of the major reasons I am in opposition to using generative AI for government lobbying stems from the replacement of a human profession. The reason lobbying exists is because humans hold different ideals and each wants their beliefs to see fruition. However, a generative AI, no matter how well it seems to mimic human mannerisms, is not a real human. As such, an Artificial Intelligence model has no actual investment in the possible outcomes of what it lobbies for. The article mentions a notable quote that applies to this qualm, noting "Lobbying firms tend to work within one state only, because there are such complex variations in law, procedure and politcal structure. With A.I. assistance in navigating these variations, it may become easier to exert power across political boundaries." This is extremely important to note because AI intervention across state boundaries could lead to unpopular and devestating decisions taking place, which would affect the residents of these states.
</br></br>
Another important motivation for my criticism of AI being used for political motives can be found in the destruction of human intervention in democratic processes. Ariticial Intelligence systems have no stake in the outcome of a given lobbying campaign. This is a notable issue because lobbying itself is human. A machine cannot understand why a human thinks the way they do and why they might oppose some law or organization. This is highlighted in the article, which states "A system that can understand political networks, if paired with the textual-generation capabilities of ChatGPT, could identify the member of Congress with the most leverage over a particular policy area -- say, corporate taxation or military spending." Artificial Intelligence systems would feel no impact from the outcomes of the lobbying campaigns they would be presenting.
</br></br>
It is also important to tie in ethical frameworks, specifically Utilitarianism, Deontology, and Virtue Ethics, when discussing the use of AI in politics.  Utilitarianism, which is defined as "What is morally right is what generates the best outcome for the largest number of people", according to Penn State University, would likely argue that this technology is not ethical or unethical. A major reason for this reasoning relates to the fact that the outcome of the AI lobbying would result in the ethical viewpoint of this framework. For instance, if the AI lobbying model managed to get a bill passed that would benefit millions of people, Utilitariansim would likely argue that this technology is ethical. However, if the model was to lobby for a bill that benefits few people, Utilitarianism would likely argue that the technology is unethical because the model did not do what generated the best outcome for the largest number of people.
</br></br>
Deontology would likely argue that this technology is unethical. Deontology is defined as "What is moral is what follows from absolute moral duties", according to Penn State University. Thus, since the AI obscures transparency and accountability in politics, it would not be following absolute moral duties. Outsourcing lobbying to non-moral agents defeats the purpose of Deontolgy and would be seen as unethical.
</br></br>

Virtue Ethics is a more complicated framework, as the ethics associated with this foundation depends on the creators goals. Thus, the creator of the technology holds the weight of if the model is ethical or not. For instance, if the creator was creating this AI lobbying model to purport bills and laws to representatives, Virtue Ethics would view this as unethical. However, if the creator made the model in hopes of promoting piece and proposing bills that would lead to the good of all, Virtue Ethics would likely view this as ethical.
</br>
Thus, to further support my claims and to defend my disdain against using AI in the political sphere, it should be noted that the three fundamental ethical frameworks we explored hold similar viewpoints about the ethics behind such technology; While AI is a powerful resource, it should not be used to undermine the voice of the people.
</br></br>
Ultimately, I am against the use of AI models for political lobbying, as I believe it is unethical. Democray depends on a human viewpoint, which while not always logical or perfect, is real. While AI can provide helpful resources and research, it should not replace human advocacy for political issues.
